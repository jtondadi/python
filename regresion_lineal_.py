# -*- coding: utf-8 -*-
"""regresion_lineal_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HSIN_KIyCdfIzngfdGPQXg5CwPwg2gUc
"""

#Según se desprende del mensaje de error, parece que Python esperaba un vector 1D
# para la variable x. El problema aquí es que cuando usas x = df.drop(['shoe'],axis = 1).values, obtienes un array 2D
# ya que estás seleccionando dos columnas (age y tall), pero np.polyfit espera recibir dos arrays 1D, uno para los valores x y otro para y.
#regresión líneal. corrección
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats


# Tus datos...
data = {
    "age": [21, 18, 20, 19, 19, 20, 21, 22, 18, 22],
    "tall": [174, 168, 170, 171, 175, 180, 173, 170, 165, 184],
    "shoe": [44, 41, 42, 42, 43.5, 45, 43, 44, 41, 46],
}
df = pd.DataFrame(data)

# Calculando la correlación...
corr = stats.pearsonr(df['tall'], df['age'])
corr2 = stats.pearsonr(df['tall'], df['shoe'])
print("corr=", corr[1])
print("corr2=", corr2)

# Preparando los datos para el ajuste lineal...
x = df['age'].values  # Esto es 1D ahora.
y = df['tall'].values  # Esto también es 1D.

# Ajuste lineal...
m, b = np.polyfit(x, y, 1)


# Visualización...
plt.scatter(x, y)
plt.plot(x, m*x + b, color='g', label='Línea de regresión')  # Añade la línea de regresión.
plt.xlabel('edad')
plt.ylabel('altura')
plt.title('Diagrama de dispersión con línea de regresión')
plt.legend()
plt.show()

#regresión líneal. corrección
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Tus datos...
data = {
    "age": [21, 18, 20, 19, 19, 20, 21, 22, 18, 22],
    "tall": [174, 168, 170, 171, 175, 180, 173, 170, 165, 184],
    "shoe": [44, 41, 42, 42, 43.5, 45, 43, 44, 41, 46],
}
df = pd.DataFrame(data)

# Calculando la correlación...
corr = stats.pearsonr(df['tall'], df['age'])
corr2 = stats.pearsonr(df['tall'], df['shoe'])
print("corr=", corr)
print("corr2=", corr2)

# Preparando los datos para el ajuste lineal...
x = df['age'].values  # Esto es 1D ahora.
y = df['tall'].values  # Esto también es 1D.


# Ajuste lineal...
m, b = np.polyfit(x, y, 1)

## predicción (transformar a 2D)
x =x.reshape(-1,1)
y =y.reshape(-1,1)
model = LinearRegression().fit(x, y)
coefIndep = model.coef_
coefDep = model.intercept_
score = r2_score (y, model.predict(x))
print ("R2 (predicción) ", score)
print ("Coef Indep", coefIndep)
print ("Coef Dep", coefDep)

# Visualización...
plt.scatter(x, y)
plt.plot(x, m*x + b, color='r', label='Línea de regresión')  # Añade la línea de regresión.
plt.xlabel('edad')
plt.ylabel('altura')
plt.title('Diagrama de dispersión con línea de regresión')
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

import pandas
data = {
    "age": [21, 18, 20, 19, 19, 20, 21, 22, 18, 22],
    "tall": [174, 168, 170, 171, 175, 180, 173, 170, 165, 184],
    "shoe": [44, 41, 42, 42, 43.5, 45, 43, 44, 41, 46],
}
df = pd.DataFrame(data)

X = df['age'].values  # Esto es 1D ahora.
y = df['tall'].values  # Esto también es 1D.

X =X.reshape(-1,1)
y = y.reshape (-1,1)


from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X, y)

from sklearn.preprocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree = 4)
X_poly = poly_reg.fit_transform(X)
poly_reg.fit(X_poly, y)
lin_reg_2 = LinearRegression()
lin_reg_2.fit(X_poly, y)

#X_grid = np.arange(min(X), max(X), 0.1)
#X_grid = X_grid.reshape((len(X_grid), 1))
plt.scatter(X, y, color = 'red')
plt.plot(X_grid, lin_reg_2.predict(poly_reg.fit_transform(X_grid)), color = 'blue')
plt.xlabel('edad')
plt.ylabel('altura')
plt.title('Diagrama de dispersión con línea de regresión')
plt.show()
#lin_reg_2.predict(poly_reg.fit_transform(6.5))